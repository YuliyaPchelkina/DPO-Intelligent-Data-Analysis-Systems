{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a806b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from cv2 import CascadeClassifier\n",
    "from PIL import Image\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import dlib\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcfa94",
   "metadata": {},
   "source": [
    "#### работа с изображениями\n",
    "- чтение из файла\n",
    "- распознавание лица\n",
    "- обрезка изображения (по контуру)\n",
    "- изменение размера изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f6611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для чтения файлов\n",
    "def viewImage(image, proba): \n",
    "    cv2.namedWindow(proba, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(proba, image)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b97754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение файлов изображений из папки\n",
    "#pictures = os.listdir('foto')\n",
    "#image = cv2.imread('foto/' + pictures[1])\n",
    "#img = image.copy()\n",
    "#height, width = img.shape[:2]\n",
    "#print(height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbc9242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures = os.listdir('foto')\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "n = 0\n",
    "k = 0\n",
    "while k < len(pictures):\n",
    "    # считываем по порядку все изображения\n",
    "    image = cv2.imread('foto/' + pictures[k])\n",
    "    \n",
    "    # работаем только с изображениями. если другие файлы - пропускаем\n",
    "    if type(image) == np.ndarray:\n",
    "        # переводим в оттенки серого\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "        # высота и ширина картинки\n",
    "        height, width = gray.shape[:2]\n",
    "\n",
    "        # каскады Хаара\n",
    "        faces = face_detector.detectMultiScale(gray, scaleFactor= 1.3, minNeighbors = 15, minSize=(100, 100))\n",
    "\n",
    "        # Добавим столбец в ndarray faces для создания массива с номером фото\n",
    "        column_to_be_added = np.array([i for i in range(1, len(faces) + 1)])\n",
    "        faces_result = np.column_stack((faces, column_to_be_added))\n",
    "\n",
    "        # обрезка фотографий. к прямоугольному контуру, определенному по признакам Хаара \n",
    "        # добавляем 50 по высоте и пропорционально уваличиваем ширину для получения квадрата\n",
    "                \n",
    "        for (x, y, w, h, i) in faces_result:\n",
    "            h1 = h\n",
    "            if y + h + 50 < height - y:\n",
    "                if ((x + w/2 + (h + 50)/2) < width) and ((x + w/2 - (h + 50)/2) > 0):\n",
    "                    h1 = h + 50\n",
    "                else:\n",
    "                    h1 = width - x\n",
    "            else:\n",
    "                if ((x + w/2 + (height-y)/2) < width) and ((x + w/2 - (height-y)/2) > 0):\n",
    "                    h1 = height-y\n",
    "                else:\n",
    "                    h1 = width - x\n",
    "            w1 = int(h1/2)\n",
    "            \n",
    "            if  (y + h1 < 0 ) or (x + int(w/2) - w1 < 0):\n",
    "                print(y + h1, x + int(w/2) - w1, pictures[k])\n",
    "            else: \n",
    "                cropped = gray[y: y + h1, x + int(w/2) - w1: x + int(w/2) + w1]\n",
    "                cv2.imwrite('foto_crop/''c'+ str(n + k + i) +'.jpg', cropped)\n",
    "            \n",
    "            \n",
    "            # масштабируем изображения к одинаковому размеру. \n",
    "            # искажения не будет, т.к. обрезка была по квадрату\n",
    "            img_resize = cv2.resize(cropped, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite('foto_resized/''r'+str(n + k + i)+'.jpg', img_resize)                     \n",
    "                    \n",
    "    else:        \n",
    "        print('error  foto/' + pictures[k])\n",
    "    n += len(faces)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95cf0f",
   "metadata": {},
   "source": [
    "#### Создание дата-сета для обучения нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557dcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем пустой дата-фрем\n",
    "df_title = {'foto': [], 'kind': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# работаем с уже обработанными изображениями\n",
    "pictures = os.listdir('foto_resized')\n",
    "#face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# для определения ключевых точек\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"utils/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "n = 0\n",
    "k = 0\n",
    "\n",
    "while k < len(pictures):\n",
    "    # считываем каждое изображение в папке\n",
    "    image = cv2.imread('foto_resized/' + pictures[k])\n",
    "    img_copy = image.copy()\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_img)    \n",
    "    \n",
    "    for face in faces:\n",
    "        # пустой список и метка для типа лица\n",
    "        list_face = []\n",
    "        #face_type = ''\n",
    "        face_mark = ''\n",
    "        \n",
    "        # определяем ключевые точки лица\n",
    "        landmarks = predictor(gray_img, face)\n",
    "        \n",
    "        # основание переносицы\n",
    "        x_n = landmarks.part(27).x\n",
    "        y_n = landmarks.part(27).y\n",
    "        \n",
    "        # подбородок\n",
    "        x_gn = landmarks.part(8).x\n",
    "        y_gn = landmarks.part(8).y\n",
    "        \n",
    "        # подвисочные выступы\n",
    "        x_zy1 = landmarks.part(1).x\n",
    "        y_zy1 = landmarks.part(1).y\n",
    "        \n",
    "        x_zy2 = landmarks.part(15).x\n",
    "        y_zy2 = landmarks.part(15).y\n",
    "    \n",
    "        # челюсть\n",
    "        x_go_left = landmarks.part(4).x\n",
    "        y_go_left = landmarks.part(4).y\n",
    "    \n",
    "        x_go_right = landmarks.part(12).x\n",
    "        y_go_right = landmarks.part(12).y\n",
    "   \n",
    "        # определяем наиболее выступающие точки челюсти\n",
    "        for n in range(5, 11):\n",
    "            if x_go_left > landmarks.part(n).x:\n",
    "                x_go_left = landmarks.part(n).x\n",
    "                y_go_left = landmarks.part(n).y\n",
    "            \n",
    "            if x_go_right < landmarks.part(n).x:\n",
    "                x_go_right = landmarks.part(n).x\n",
    "                y_go_right = landmarks.part(n).y    \n",
    "\n",
    "        # анатомическая высота        \n",
    "        n_gn = round(math.sqrt((x_n - x_gn)**2 + (y_n - y_gn)**2))\n",
    "        # анатомическая ширина\n",
    "        zy_zy = round(math.sqrt((x_zy1 - x_zy2)**2 + (y_zy1 - y_zy2)**2))\n",
    "\n",
    "        # коэффициенты для подсчета углов наклона\n",
    "        m1 = (x_go_right - x_zy2) \n",
    "        n1 = (y_go_right - y_zy2)\n",
    "        \n",
    "        m3 = (x_go_left - x_zy1) \n",
    "        n3 = (y_go_left - y_zy1) \n",
    "        \n",
    "        m2 = (x_go_left - x_go_right)\n",
    "        n2 = (y_go_left - y_go_right)\n",
    "       \n",
    "        # углы наклона касательных\n",
    "        k_right = math.acos((m1*m2 + n1*n2)/((math.sqrt(m1*m1 + n1*n1))*(math.sqrt(m2*m2 + n2*n2))))\n",
    "        angle1 = 90 - round((k_right/math.pi)*180)\n",
    "        \n",
    "        k_left = math.acos((m1*m2 + n1*n2)/((math.sqrt(m1*m1 + n1*n1))*(math.sqrt(m2*m2 + n2*n2))))\n",
    "        angle2 = 90 - round((k_left/math.pi)*180)\n",
    "            \n",
    "        # определяем тип лица\n",
    "        if (angle1 > 37) or (angle2 > 27):\n",
    "            face_mark = '2'\n",
    "        elif n_gn + 13 < zy_zy:\n",
    "            face_mark = '1'\n",
    "        else:\n",
    "            face_mark = '0'\n",
    "        \n",
    "        # добавляем в список словарь   \n",
    "        list_face.append({'foto': pictures[k], 'kind': face_mark})\n",
    "        \n",
    "        # в датафрейм добавляем данные\n",
    "        df = df.append(list_face)   \n",
    "    n += len(faces)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38b673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датафрейм\n",
    "df.to_csv('foto_frame1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
